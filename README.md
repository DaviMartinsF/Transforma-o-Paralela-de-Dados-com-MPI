# Transforma√ß√£o Paralela de Vetor com MPI

Este projeto demonstra um padr√£o b√°sico de computa√ß√£o paralela "Map" (mapear/transformar) usando MPI (Message Passing Interface).

O programa inicializa um vetor de `N` elementos no processo mestre (rank 0), distribui por√ß√µes desse vetor para todos os processos dispon√≠veis, aplica uma transforma√ß√£o em paralelo (elevar ao quadrado) e, em seguida, coleta os resultados de volta no processo mestre para valida√ß√£o.

## üìù Descri√ß√£o do Processo

O fluxo de trabalho segue o modelo Scatter-Gather:

1.  **Inicializa√ß√£o:** O processo 0 aloca e preenche um vetor `original_data` com `DATA_SIZE` elementos (1 a 100).
2.  **Distribui√ß√£o (Scatter):** O processo 0 usa `MPI_Scatter` para dividir `original_data` em `P` peda√ßos iguais e envia um peda√ßo para cada processo (incluindo ele mesmo).
3.  **Transforma√ß√£o (Map):** Cada processo (`id` de 0 a P-1) recebe sua por√ß√£o em `local_data` e aplica a fun√ß√£o `transform_data` (calculando $x^2$) em seus elementos locais.
4.  **Coleta (Gather):** Cada processo envia seu vetor `local_data` transformado de volta para o processo 0, que os re√∫ne em ordem no vetor `gathered_data` usando `MPI_Gather`.
5.  **Valida√ß√£o:** O processo 0 calcula sequencialmente o resultado esperado e o compara com o `gathered_data` recebido do processamento paralelo. Ele imprime "Sucesso" ou "Falha".

## üõ†Ô∏è Requisitos

* Um compilador C (como `gcc`).
* Uma implementa√ß√£o do MPI (como **Open MPI**).

## üöÄ Como Compilar

Para compilar o programa, utilize o compilador MPI wrapper `mpicc`:

```bash
mpicc -o transforma_mpi transforma_mpi.c
```
## üõ†Ô∏è Como Compilar e Executar
**Compila√ßao** 
Use mpirun para executar o programa, especificando o n√∫mero de processos (-np) desejado.
```bash
mpirun -np <numero_de_processos> ./transforma_mpi

```
**Exemplo com 4 processos**
```bash
mpirun -np 4 ./transforma_mpi

```
**Saida Esperada: **
```bash
Sucesso! O resultado paralelo foi validado corretamente.

```
## ‚ùó Importante: Limita√ß√µes da Execu√ß√£o
1. **Divisibilidade de processos**
Esta vers√£o do c√≥digo usa `MPI_Scatter` e `MPI_Gather` simples, que exigem que os dados possam ser divididos igualmente entre os processos.

* DATA_SIZE (definido no c√≥digo como 100) deve ser perfeitamente divis√≠vel pelo n√∫mero de processos (P) que voc√™ usa no mpirun.

Valores de `-np` que funcionar√£o: `1, 2, 4, 5, 10, 20, 25, 50, 100`

Valores de `-np` que falhar√£o (intencionalmente): `3, 6, 7, 8, ...`

Se voc√™ tentar usar um n√∫mero n√£o-divisor (ex: 3), o programa ir√° abortar com a mensagem de erro que implementamos:
```bash
Erro: DATA_SIZE (100) n√£o √© divis√≠vel por P (3)
MPI_ABORT was invoked on rank 0...

```

2. **"Not enough slots" (Oversubscribing)**
Por padr√£o, o MPI n√£o permite que voc√™ execute mais processos do que o n√∫mero de n√∫cleos f√≠sicos da sua CPU (chamados de "slots"). Se voc√™ tem 4 n√∫cleos e tenta rodar com -np 5, voc√™ ver√° este erro:

```bash
There are not enough slots available in the system...

```
Para for√ßar o MPI a executar mais processos do que os n√∫cleos dispon√≠veis (√∫til para testes), use a flag `--oversubscribe`:

```bash
#Exemplo para rodar com 5 processos em uma m√°quina de 4 n√∫cleos
mpirun -np 5 --oversubscribe ./transforma_mpi

```

## ‚úíÔ∏è Autor
* Davi Martins Figueiredo - 10374878
